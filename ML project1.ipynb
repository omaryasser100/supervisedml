{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "19abab3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 80)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#libraies we need\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "#reviewing the data\n",
    "df=pd.read_csv('train.csv')\n",
    "l1=df.columns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('SalePrice',axis=1), df['SalePrice'],                 # Features and target\n",
    "    test_size=0.2,        # 20% for testing\n",
    "    random_state=42,      # For reproducibility\n",
    ")\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "886ed616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual classiication of columns based wether the data is numerical,nominal or ordinal data \n",
    "numerical=X_train[['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "              'LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "              'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch',\n",
    "              '3SsnPorch','ScreenPorch','PoolArea','MiscVal']]\n",
    "nominal=X_train[['Street','Alley','LandContour','LotConfig','Neighborhood','Condition1',\n",
    "           'Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl',\n",
    "           'Exterior1st','Exterior2nd','MasVnrType','Foundation','Heating','CentralAir',\n",
    "           'GarageType','GarageFinish','MiscFeature','SaleType','SaleCondition']]\n",
    "ordinal=X_train[['MSSubClass','MSZoning','LotShape','Utilities','LandSlope','OverallQual','OverallCond'\n",
    "           ,'YearBuilt','YearRemodAdd','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "           'HeatingQC','Electrical','KitchenQual','Functional','FireplaceQu','GarageYrBlt','GarageFinish','GarageQual','GarageCond',\n",
    "           'PavedDrive','PoolQC','Fence','MoSold','YrSold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a94ce242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to check for dominant columns and excecive nans in order to remove as they are not necessary for the model\n",
    "def get_low_information_columns(df, dominance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Finds columns where one category dominates (occurs in >= dominance_threshold proportion of rows).\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - column_list: list of columns to check\n",
    "    - dominance_threshold: float (0 to 1), threshold for dominant category\n",
    "    \n",
    "    Returns:\n",
    "    - List of column names with dominant single-category values\n",
    "    \"\"\"\n",
    "    low_info_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        top_freq = df[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "        if top_freq >= dominance_threshold:\n",
    "            low_info_cols.append(col)\n",
    "\n",
    "    return low_info_cols\n",
    "\n",
    "def get_columns_with_excessive_nans(df, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Returns columns from column_list where the proportion of NaN values exceeds the given threshold.\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - column_list: list of column names to check\n",
    "    - threshold: float between 0 and 1 (e.g. 0.5 means drop if >50% NaNs)\n",
    "    Returns:\n",
    "    - List of column names to consider dropping\n",
    "    \"\"\"\n",
    "    total_rows = len(df)\n",
    "    drop_candidates = []\n",
    "    for col in df.columns:\n",
    "        nan_ratio = df[col].isna().sum() / total_rows\n",
    "        if nan_ratio > threshold:\n",
    "            drop_candidates.append(col)\n",
    "    return drop_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "829eae09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 16)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting columns to drop based on their dominance and nans number\n",
    "\n",
    "numerical_drop=['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','BedroomAbvGr','GarageCars']\n",
    "\n",
    "ordinal_drops=get_low_information_columns(ordinal,0.7)\n",
    "nominal_drops=get_low_information_columns(nominal,0.7)\n",
    "\n",
    "nan_numerical=get_columns_with_excessive_nans(numerical,0.7)\n",
    "nan_nominal=get_columns_with_excessive_nans(nominal,0.7)\n",
    "nan_ordinal=get_columns_with_excessive_nans(ordinal,0.7)\n",
    "\n",
    "tot_num_drop=list(set(numerical_drop+nan_numerical))\n",
    "tot_nom_drop=list(set(nominal_drops+nan_nominal))\n",
    "tot_ord_drop=list(set(ordinal_drops+nan_ordinal))\n",
    "tot_num_drop\n",
    "#dropat\n",
    "\n",
    "numerical_v2=numerical.drop(tot_num_drop,axis=1)\n",
    "nominal_v2=nominal.drop(tot_nom_drop,axis=1)\n",
    "ordinal_v2=ordinal.drop(tot_ord_drop,axis=1)\n",
    "ordinal_v2=ordinal_v2.drop('MoSold',axis=1)\n",
    "ordinal_v2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c47558eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Utilities',\n",
       " 'LandSlope',\n",
       " 'ExterCond',\n",
       " 'BsmtCond',\n",
       " 'BsmtFinType2',\n",
       " 'Electrical',\n",
       " 'Functional',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'PoolQC',\n",
       " 'Fence']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b17affe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 8)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature engineering\n",
    "full_bath=['BsmtFullBath','FullBath']\n",
    "half_bath=['BsmtHalfBath','HalfBath']\n",
    "tot_area=['LotFrontage','LotArea','MasVnrArea','TotalBsmtSF','1stFlrSF','2ndFlrSF','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch',\n",
    "          'PoolArea']\n",
    "#Adding all th area columns of the house into a single area of the house\n",
    "numerical_v2['total_area']=numerical_v2[tot_area].sum(axis=1)\n",
    "numerical_v2.drop(tot_area,axis=1,inplace=True)\n",
    "#Adding all the full bathrooms and half bathrooms into a single column\n",
    "numerical_v2['totalbathreoams']=numerical_v2[full_bath].sum(axis=1)+(numerical_v2[half_bath].sum(axis=1)*0.5)\n",
    "numerical_v2=numerical_v2.drop(full_bath,axis=1)\n",
    "numerical_v2=numerical_v2.drop(half_bath,axis=1)\n",
    "\n",
    "\n",
    "significant=['LowQualFinSF','GrLivArea','KitchenAbvGr','TotRmsAbvGrd']#expected signeficant columns from data understanding\n",
    "numerical_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1bebb532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.2f}",
         "type": "heatmap",
         "x": [
          "LowQualFinSF",
          "GrLivArea",
          "KitchenAbvGr",
          "TotRmsAbvGrd",
          "Fireplaces",
          "MiscVal",
          "total_area",
          "totalbathreoams"
         ],
         "xaxis": "x",
         "y": [
          "LowQualFinSF",
          "GrLivArea",
          "KitchenAbvGr",
          "TotRmsAbvGrd",
          "Fireplaces",
          "MiscVal",
          "total_area",
          "totalbathreoams"
         ],
         "yaxis": "y",
         "z": {
          "bdata": "AAAAAAAA8D+Il6P8xg3CP/bOPLoV3Y8/0eeSXK30wD92I9u49rKTv6iNNpIHmoa/JZS32uUQfT+Umn9mzG+iv4iXo/zGDcI/AAAAAAAA8D95PVC+2vG6P1nLVZNRQ+o/VVEZVtRw3T923qA02+M8P3h2Jtty7tU/BmDZu6uR4j/2zjy6Fd2PP3k9UL7a8bo/AAAAAAAA8D94rN5c9IDRPw5FBm9LGL+/2mVPXOmWsD+IW/UaI1+bv9hBWcqG3qI/0eeSXK30wD9Zy1WTUUPqP3is3lz0gNE/AAAAAAAA8D+LDqMsMHHUP6TEPll12J4/hRB/Y3E/zz/rfsir3q3cP3Yj27j2spO/VVEZVtRw3T8ORQZvSxi/v4sOoywwcdQ/AAAAAAAA8D80p/BJVl1xPwhY+Kz70tM/VSVm4Jnb0z+ojTaSB5qGv3beoDTb4zw/2mVPXOmWsD+kxD5ZddiePzSn8ElWXXE/AAAAAAAA8D+DCncjOfmhP6222X+VBJu/JZS32uUQfT94dibbcu7VP4hb9RojX5u/hRB/Y3E/zz8IWPis+9LTP4MKdyM5+aE/AAAAAAAA8D8vPKd7Zt/QP5Saf2bMb6K/BmDZu6uR4j/YQVnKht6iP+t+yKverdw/VSVm4Jnb0z+tttl/lQSbvy88p3tm39A/AAAAAAAA8D8=",
          "dtype": "f8",
          "shape": "8, 8"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(5,48,97)"
          ],
          [
           0.1,
           "rgb(33,102,172)"
          ],
          [
           0.2,
           "rgb(67,147,195)"
          ],
          [
           0.3,
           "rgb(146,197,222)"
          ],
          [
           0.4,
           "rgb(209,229,240)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(253,219,199)"
          ],
          [
           0.7,
           "rgb(244,165,130)"
          ],
          [
           0.8,
           "rgb(214,96,77)"
          ],
          [
           0.9,
           "rgb(178,24,43)"
          ],
          [
           1,
           "rgb(103,0,31)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Correlation Matrix Heatmap"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "Features"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Features"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the correlation matrix\n",
    "corr_matrix = numerical_v2.corr(numeric_only=True)\n",
    "# Convert it to long format for Plotly\n",
    "corr_long = corr_matrix.reset_index().melt(id_vars='index')\n",
    "corr_long.columns = ['Feature1', 'Feature2', 'Correlation']\n",
    "# Create Plotly heatmap\n",
    "fig = px.imshow(\n",
    "    corr_matrix,\n",
    "    text_auto='.2f',\n",
    "    color_continuous_scale='RdBu_r',\n",
    "    title='Correlation Matrix Heatmap',\n",
    "    aspect='auto'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Features',\n",
    "    yaxis_title='Features',\n",
    "    xaxis_tickangle=-45\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3e65c0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>total_area</th>\n",
       "      <th>totalbathreoams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11642.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10686.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10928.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10515.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8317.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12485.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12023.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10532.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10491.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7618.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LowQualFinSF  KitchenAbvGr  TotRmsAbvGrd  Fireplaces  total_area  \\\n",
       "0                0             1             5           0     11642.0   \n",
       "1                0             1             7           1     10686.0   \n",
       "2                0             1             4           0     10928.0   \n",
       "3                0             1             7           2     10515.0   \n",
       "4                0             1             6           1      8317.0   \n",
       "...            ...           ...           ...         ...         ...   \n",
       "1163             0             1             6           1     12485.0   \n",
       "1164             0             1             7           2     12023.0   \n",
       "1165             0             1             5           0     10532.0   \n",
       "1166             0             1             7           1     10491.0   \n",
       "1167             0             1             7           1      7618.0   \n",
       "\n",
       "      totalbathreoams  \n",
       "0                 2.0  \n",
       "1                 2.5  \n",
       "2                 1.0  \n",
       "3                 2.5  \n",
       "4                 2.0  \n",
       "...               ...  \n",
       "1163              2.0  \n",
       "1164              3.0  \n",
       "1165              2.0  \n",
       "1166              1.5  \n",
       "1167              2.0  \n",
       "\n",
       "[1168 rows x 6 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_v2=numerical_v2.drop('MiscVal',axis=1)\n",
    "numerical_v2=numerical_v2.drop('GrLivArea',axis=1)\n",
    "numerical_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f23fc9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 85)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nominal encoding \n",
    "#nominal encoding \n",
    "encoded_nominal=pd.DataFrame()\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# Fit and transform only the specified columns\n",
    "encoded_data = ohe.fit_transform(nominal_v2)\n",
    "\n",
    "# Get the new column names for encoded features\n",
    "encoded_cols = ohe.get_feature_names_out(nominal_v2.columns)\n",
    "\n",
    "# Create a DataFrame with the encoded columns\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoded_cols, index=nominal_v2.index)\n",
    "\n",
    "# Drop original columns and concatenate the encoded ones\n",
    "\n",
    "encoded_nominal = pd.concat([encoded_nominal, encoded_df], axis=1)\n",
    "encoded_nominal.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2ada4ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 16)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ordinal encoding\n",
    "#small function to show all the unique values of each column (numerical are sorted) in order to make the order manually for the encoder \n",
    "'''for col in ordinal_v2.columns:\n",
    "    uniques = sorted(ordinal_v2[col].dropna().unique())\n",
    "\n",
    "    cleaned_uniques = []\n",
    "    for val in uniques:\n",
    "        if isinstance(val, (np.integer, int)):\n",
    "            cleaned_uniques.append(int(val))\n",
    "        elif isinstance(val, (np.floating, float)):\n",
    "            # Convert float to int if it's a whole number like 1900.0\n",
    "            cleaned_uniques.append(int(val) if val.is_integer() else float(val))\n",
    "        else:\n",
    "            cleaned_uniques.append(val)\n",
    "\n",
    "    print(f\"{col}: {cleaned_uniques}\")\n",
    "'''\n",
    "\n",
    "\n",
    "orders_list=[[20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 160, 180, 190],\n",
    "             ['Reg','IR1', 'IR2', 'IR3'],\n",
    "             [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "             [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "             [1872, 1875, 1880, 1882, 1885, 1890, 1892, 1893, 1898, 1900, 1904, 1905, 1906, 1908,\n",
    "              1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917,1918, 1919, 1920, 1921, 1922, 1923, \n",
    "              1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1934, 1935, 1936, 1937, 1938,\n",
    "              1939, 1940,1941, 1942, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, \n",
    "              1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964,1965, 1966, 1967, 1968, \n",
    "              1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982,\n",
    "              1983, 1984, 1985,1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, \n",
    "              1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010],\n",
    "             [1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, \n",
    "              1964, 1965, 1966, 1967, 1968, 1969, 1970,1971, 1972, 1973, 1974, 1975, 1976, 1977, \n",
    "              1978, 1979, 1980, 1981, 1982, 1983,1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, \n",
    "              1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005,\n",
    "              2006, 2007, 2008, 2009, 2010],\n",
    "             ['Ex', 'Gd', 'TA', 'Fa'],\n",
    "             ['Ex', 'Gd', 'TA', 'Fa'],\n",
    "             [ 'Gd','Av', 'Mn', 'No'],\n",
    "             ['GLQ','ALQ', 'BLQ', 'Rec', 'LwQ',  'Unf'],\n",
    "             ['Ex', 'Gd', 'TA', 'Fa', 'Po'],\n",
    "             ['Ex', 'Gd', 'TA', 'Fa'],\n",
    "             ['Ex', 'Gd', 'TA', 'Fa', 'Po'],\n",
    "             [1900, 1906, 1908, 1910, 1914, 1915, 1916, 1918, 1920, 1921, 1922, 1923, 1924, 1925,\n",
    "              1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939,\n",
    "              1940, 1941, 1942, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955,\n",
    "              1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969,\n",
    "              1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983,\n",
    "              1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997,\n",
    "              1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010],\n",
    "              ['Fin', 'RFn', 'Unf'],\n",
    "               [2006, 2007, 2008, 2009, 2010]]\n",
    "\n",
    "ordinal_cols=ordinal_v2.columns\n",
    "encoder = OrdinalEncoder(categories=orders_list,handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "ordinal_v2[ordinal_cols] = encoder.fit_transform(ordinal_v2[ordinal_cols])\n",
    "ordinal_encoded=ordinal_v2\n",
    "ordinal_encoded.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "582a2cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 107)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final data frame (nesceds scaling and ready for ML)\n",
    "numerical_v2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "\n",
    "numerical_v3=scaler.fit_transform(numerical_v2)\n",
    "numerical_v4=pd.DataFrame(numerical_v3,columns=numerical_v2.columns)\n",
    "final_train=pd.concat([numerical_v4,encoded_nominal,ordinal_encoded],axis=1)\n",
    "final_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4c56dd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        896\n",
       "1       1329\n",
       "2        928\n",
       "3        926\n",
       "4       1280\n",
       "        ... \n",
       "1454     546\n",
       "1455     546\n",
       "1456    1224\n",
       "1457     970\n",
       "1458     996\n",
       "Name: 1stFlrSF, Length: 1459, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encapsulate in a pipeline in the future \n",
    "\n",
    "df=pd.read_csv('test.csv')\n",
    "l1=df.columns\n",
    "df['1stFlrSF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "03b6d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual classiication of columns based wether the data is numerical,nominal or ordinal data \n",
    "numerical_test=X_test[['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "              'LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "              'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch',\n",
    "              '3SsnPorch','ScreenPorch','PoolArea','MiscVal']]\n",
    "nominal_test=X_test[['Street','Alley','LandContour','LotConfig','Neighborhood','Condition1',\n",
    "           'Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl',\n",
    "           'Exterior1st','Exterior2nd','MasVnrType','Foundation','Heating','CentralAir',\n",
    "           'GarageType','GarageFinish','MiscFeature','SaleType','SaleCondition']]\n",
    "ordinal_test=X_test[['MSSubClass','MSZoning','LotShape','Utilities','LandSlope','OverallQual','OverallCond'\n",
    "           ,'YearBuilt','YearRemodAdd','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "           'HeatingQC','Electrical','KitchenQual','Functional','FireplaceQu','GarageYrBlt','GarageFinish','GarageQual','GarageCond',\n",
    "           'PavedDrive','PoolQC','Fence','MoSold','YrSold']]\n",
    "\n",
    "'''ordinal_v2.shape\n",
    "\n",
    "\n",
    "ordinal_test=ordinal_test.drop(tot_ord_drop,axis=1)\n",
    "\n",
    "ordinal_test.drop('MoSold',axis=1,inplace=True)\n",
    "ordinal_v2.shape\n",
    "ordinal_test.shape\n",
    "numerical_test=numerical_test.drop(tot_num_drop,axis=1)\n",
    "numerical_test.shape\n",
    "numerical_v2\n",
    "numerical_test.head()'''\n",
    "\n",
    "numerical_test=numerical_test.drop(tot_num_drop,axis=1)\n",
    "nominal_test=nominal_test.drop(tot_nom_drop,axis=1)\n",
    "ordinal_test=ordinal_test.drop(tot_ord_drop,axis=1)\n",
    "ordinal_test=ordinal_test.drop('MoSold',axis=1)\n",
    "\n",
    "#feature engineering\n",
    "\n",
    "#Adding all th area columns of the house into a single area of the house\n",
    "numerical_test['total_area']=numerical_test[tot_area].sum(axis=1)\n",
    "numerical_test.drop(tot_area,axis=1,inplace=True)\n",
    "#Adding all the full bathrooms and half bathrooms into a single column\n",
    "numerical_test['totalbathreoams']=numerical_test[full_bath].sum(axis=1)+(numerical_test[half_bath].sum(axis=1)*0.5)\n",
    "numerical_test=numerical_test.drop(full_bath,axis=1)\n",
    "numerical_test=numerical_test.drop(half_bath,axis=1)\n",
    "numerical_test=numerical_test.drop('MiscVal',axis=1)\n",
    "numerical_test=numerical_test.drop('GrLivArea',axis=1)\n",
    "\n",
    "#nominal encoding \n",
    "encoded_nominal_test=pd.DataFrame()\n",
    " \n",
    "\n",
    "# Fit and transform only the specified columns\n",
    "encoded_data = ohe.transform(nominal_test)\n",
    "\n",
    "# Get the new column names for encoded features\n",
    "encoded_cols = ohe.get_feature_names_out(nominal_test.columns)\n",
    "\n",
    "# Create a DataFrame with the encoded columns\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoded_cols, index=nominal_test.index)\n",
    "\n",
    "# Drop original columns and concatenate the encoded ones\n",
    "\n",
    "encoded_nominal_test = pd.concat([encoded_nominal_test, encoded_df], axis=1)\n",
    "\n",
    "\n",
    "ordinal_cols=ordinal_test.columns\n",
    "ordinal_test[ordinal_cols] = encoder.transform(ordinal_test[ordinal_cols])\n",
    "ordinal_encoded_test=ordinal_test\n",
    "ordinal_encoded_test\n",
    "\n",
    "\n",
    "ordinal_encoded_test.shape\n",
    "\n",
    "\n",
    "numerical_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_test_v3=scaler.fit_transform(numerical_test)\n",
    "numerical_test_v4=pd.DataFrame(numerical_test_v3,columns=numerical_test.columns)\n",
    "final_test=pd.concat([numerical_test_v4,encoded_nominal_test,ordinal_encoded_test],axis=1)\n",
    "y_train.shape\n",
    "\n",
    "\n",
    "\n",
    "X_train=final_train\n",
    "X_test=final_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "93f41314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Averaging MSE: 1849286806.59\n",
      "Simple Averaging R² Score: 0.7589\n"
     ]
    }
   ],
   "source": [
    "#First try using sbase reggresors with average majority voting ensemble\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define base regressors\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "svr = SVR()\n",
    "\n",
    "# Train them\n",
    "lr.fit(final_train, y_train)\n",
    "rf.fit(final_train, y_train)\n",
    "svr.fit(final_train, y_train)\n",
    "\n",
    "# Predict\n",
    "lr_pred = lr.predict(final_test)\n",
    "rf_pred = rf.predict(final_test)\n",
    "svr_pred = svr.predict(final_test)\n",
    "\n",
    "# Simple average\n",
    "avg_pred = (lr_pred + rf_pred + svr_pred) / 3\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, avg_pred)\n",
    "r2 = r2_score(y_test, avg_pred)\n",
    "\n",
    "print(f\"Simple Averaging MSE: {mse:.2f}\")\n",
    "print(f\"Simple Averaging R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00171fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5233ac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 725\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 181441.541952\n",
      "Simple Averaging MSE: 1053286220.63\n",
      "Simple Averaging RMSE: 32454.37\n",
      "Simple Averaging R² Score: 0.8627\n"
     ]
    }
   ],
   "source": [
    "#more powerful reggresors (xg boost,LGBMRegressor)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Initialize models\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "xgb = XGBRegressor(random_state=42, verbosity=0)\n",
    "lgb = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Fit models\n",
    "lr.fit(final_train, y_train)\n",
    "rf.fit(final_train, y_train)\n",
    "xgb.fit(final_train, y_train)\n",
    "lgb.fit(final_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "lr_pred = lr.predict(final_test)\n",
    "rf_pred = rf.predict(final_test)\n",
    "xgb_pred = xgb.predict(final_test)\n",
    "lgb_pred = lgb.predict(final_test)\n",
    "\n",
    "# Average predictions\n",
    "avg_pred = (lr_pred + rf_pred + xgb_pred + lgb_pred) / 4\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, avg_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, avg_pred)\n",
    "\n",
    "print(f\"Simple Averaging MSE: {mse:.2f}\")\n",
    "print(f\"Simple Averaging RMSE: {rmse:.2f}\")\n",
    "print(f\"Simple Averaging R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8f89aca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weights: [0.38394124 0.56662295 0.         0.04943581]\n",
      "Optimized R² score: 0.8681\n",
      "Weighted Averaging MSE: 1012033621.60\n",
      "Weighted Averaging RMSE: 31812.48\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Example: you already have these predictions from your trained models on X_test\n",
    "# lr_pred = lr.predict(X_test_encoded)\n",
    "# rf_pred = rf.predict(X_test_encoded)\n",
    "# xgb_pred = xgb.predict(X_test_encoded)\n",
    "# lgb_pred = lgb.predict(X_test_encoded)\n",
    "\n",
    "# For demonstration, I will assume lr_pred, rf_pred, xgb_pred, lgb_pred are numpy arrays\n",
    "# y_test is the true target values\n",
    "\n",
    "def objective(weights):\n",
    "    # Weighted sum of predictions\n",
    "    weighted_pred = (\n",
    "        weights[0] * lr_pred +\n",
    "        weights[1] * rf_pred +\n",
    "        weights[2] * xgb_pred +\n",
    "        weights[3] * lgb_pred\n",
    "    )\n",
    "    # We want to maximize R2, so minimize negative R2\n",
    "    return -r2_score(y_test, weighted_pred)\n",
    "\n",
    "# Constraint: weights must sum to 1\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "\n",
    "# Bounds: each weight between 0 and 1\n",
    "bounds = [(0,1)] * 4\n",
    "\n",
    "# Initial guess: equal weights\n",
    "init_guess = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "result = minimize(objective, init_guess, bounds=bounds, constraints=constraints)\n",
    "\n",
    "best_weights = result.x\n",
    "best_r2 = -result.fun\n",
    "\n",
    "print(f\"Optimized weights: {best_weights}\")\n",
    "print(f\"Optimized R² score: {best_r2:.4f}\")\n",
    "\n",
    "# Calculate final weighted prediction with optimized weights\n",
    "final_pred = (\n",
    "    best_weights[0] * lr_pred +\n",
    "    best_weights[1] * rf_pred +\n",
    "    best_weights[2] * xgb_pred +\n",
    "    best_weights[3] * lgb_pred\n",
    ")\n",
    "\n",
    "# Optionally calculate MSE and RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, final_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Weighted Averaging MSE: {mse:.2f}\")\n",
    "print(f\"Weighted Averaging RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "506eeead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE: 1184877105.84\n",
      "Bagging Regressor RMSE: 34422.04\n",
      "Bagging Regressor R² Score: 0.8455\n"
     ]
    }
   ],
   "source": [
    "#bagging regressors\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize base model (Decision Tree)\n",
    "base_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Initialize Bagging Regressor with base model\n",
    "bagging = BaggingRegressor(estimator=base_model,\n",
    "                           n_estimators=50,\n",
    "                           random_state=42)\n",
    "\n",
    "# Fit on training data\n",
    "bagging.fit(final_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = bagging.predict(final_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Bagging Regressor MSE: {mse:.2f}\")\n",
    "print(f\"Bagging Regressor RMSE: {rmse:.2f}\")\n",
    "print(f\"Bagging Regressor R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "6f3cfe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 725\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 181441.541952\n",
      "Voting Regressor MSE: 1053286220.63\n",
      "Voting Regressor RMSE: 32454.37\n",
      "Voting Regressor R² Score: 0.8627\n"
     ]
    }
   ],
   "source": [
    "#voting reggresor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize individual models\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "lgb = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Initialize Voting Regressor\n",
    "voting_reg = VotingRegressor(estimators=[\n",
    "    ('lr', lr),\n",
    "    ('rf', rf),\n",
    "    ('xgb', xgb),\n",
    "    ('lgb', lgb)\n",
    "])\n",
    "\n",
    "# Fit Voting Regressor on training data\n",
    "voting_reg.fit(final_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = voting_reg.predict(final_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Voting Regressor MSE: {mse:.2f}\")\n",
    "print(f\"Voting Regressor RMSE: {rmse:.2f}\")\n",
    "print(f\"Voting Regressor R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "713fba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor with cv=10 MSE: 1184466318.14\n",
      "Stacking Regressor with cv=10 RMSE: 34416.08\n",
      "Stacking Regressor with cv=10 R² Score: 0.8456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Base models\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('xgb', XGBRegressor(random_state=42)),\n",
    "    ('lgb', LGBMRegressor(random_state=42))\n",
    "]\n",
    "\n",
    "# Meta-model: Ridge Regression (simple, effective)\n",
    "meta_regressor = Ridge(alpha=1.0)\n",
    "\n",
    "# Initialize Stacking with cv=10\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=meta_regressor,\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "stacking_reg.fit(final_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacking_reg.predict(final_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Regressor with cv=10 MSE: {mse:.2f}\")\n",
    "print(f\"Stacking Regressor with cv=10 RMSE: {rmse:.2f}\")\n",
    "print(f\"Stacking Regressor with cv=10 R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d534149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 697\n",
      "[LightGBM] [Info] Number of data points in the train set: 934, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 181034.540685\n",
      "Blending MSE: 1271865026.99\n",
      "Blending RMSE: 35663.22\n",
      "Blending R² Score: 0.8342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Split your existing training data into base training and holdout (for blending)\n",
    "X_base_train, X_holdout, y_base_train, y_holdout = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Initialize base models\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "lgb = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Step 3: Train base models on the base training set only\n",
    "rf.fit(X_base_train, y_base_train)\n",
    "xgb.fit(X_base_train, y_base_train)\n",
    "lgb.fit(X_base_train, y_base_train)\n",
    "\n",
    "# Step 4: Generate predictions of base models on the holdout set (meta-model training data)\n",
    "rf_holdout_pred = rf.predict(X_holdout)\n",
    "xgb_holdout_pred = xgb.predict(X_holdout)\n",
    "lgb_holdout_pred = lgb.predict(X_holdout)\n",
    "\n",
    "# Step 5: Stack these predictions as features to train the meta-model (blender)\n",
    "X_blend_train = np.column_stack((rf_holdout_pred, xgb_holdout_pred, lgb_holdout_pred))\n",
    "\n",
    "# Step 6: Initialize and train meta-model (e.g., Ridge)\n",
    "meta_model = Ridge(alpha=1.0)\n",
    "meta_model.fit(X_blend_train, y_holdout)\n",
    "\n",
    "# Step 7: Predict base models on the original test set\n",
    "rf_test_pred = rf.predict(X_test)\n",
    "xgb_test_pred = xgb.predict(X_test)\n",
    "lgb_test_pred = lgb.predict(X_test)\n",
    "\n",
    "# Step 8: Stack test predictions as input for meta-model\n",
    "X_blend_test = np.column_stack((rf_test_pred, xgb_test_pred, lgb_test_pred))\n",
    "\n",
    "# Step 9: Make final blended predictions\n",
    "y_pred = meta_model.predict(X_blend_test)\n",
    "\n",
    "# Step 10: Evaluate the blended predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Blending MSE: {mse:.2f}\")\n",
    "print(f\"Blending RMSE: {rmse:.2f}\")\n",
    "print(f\"Blending R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6ba1fffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 21:06:26,311] A new study created in memory with name: no-name-931572d3-f38a-4d1a-9c22-c743bed27893\n",
      "[I 2025-05-16 21:06:28,702] Trial 0 finished with value: 0.8483250141143799 and parameters: {'n_estimators': 766, 'max_depth': 8, 'learning_rate': 0.157678805850236, 'subsample': 0.962307875928265, 'colsample_bytree': 0.6493699114125192, 'gamma': 4.595263436350335, 'reg_alpha': 0.6784589423513276, 'reg_lambda': 1.611138017081778}. Best is trial 0 with value: 0.8483250141143799.\n",
      "[I 2025-05-16 21:06:29,939] Trial 1 finished with value: 0.8424611687660217 and parameters: {'n_estimators': 595, 'max_depth': 8, 'learning_rate': 0.2823724672505149, 'subsample': 0.6336711175981, 'colsample_bytree': 0.81966782536045, 'gamma': 1.0963715038886424, 'reg_alpha': 1.5910966367000514, 'reg_lambda': 1.2891854761641113}. Best is trial 0 with value: 0.8483250141143799.\n",
      "[I 2025-05-16 21:06:33,291] Trial 2 finished with value: 0.8662516474723816 and parameters: {'n_estimators': 988, 'max_depth': 10, 'learning_rate': 0.03588493355786807, 'subsample': 0.6569367701082689, 'colsample_bytree': 0.6712455740702384, 'gamma': 2.751969545729392, 'reg_alpha': 0.040685752315746004, 'reg_lambda': 1.0004125560943211}. Best is trial 2 with value: 0.8662516474723816.\n",
      "[I 2025-05-16 21:06:33,939] Trial 3 finished with value: 0.8787325024604797 and parameters: {'n_estimators': 462, 'max_depth': 3, 'learning_rate': 0.019268122386542887, 'subsample': 0.8900318712849495, 'colsample_bytree': 0.7194480827463471, 'gamma': 1.291681007354419, 'reg_alpha': 1.0640402728156544, 'reg_lambda': 1.2911462948283572}. Best is trial 3 with value: 0.8787325024604797.\n",
      "[I 2025-05-16 21:06:34,573] Trial 4 finished with value: 0.8525574207305908 and parameters: {'n_estimators': 308, 'max_depth': 6, 'learning_rate': 0.07970453405344272, 'subsample': 0.7238796144320512, 'colsample_bytree': 0.8203844062750144, 'gamma': 3.027952073954378, 'reg_alpha': 0.9009793892282918, 'reg_lambda': 0.7884526160743}. Best is trial 3 with value: 0.8787325024604797.\n",
      "[I 2025-05-16 21:06:36,572] Trial 5 finished with value: 0.860539436340332 and parameters: {'n_estimators': 1164, 'max_depth': 5, 'learning_rate': 0.026502657293851414, 'subsample': 0.7798271302314297, 'colsample_bytree': 0.9263413024785636, 'gamma': 2.350606023208121, 'reg_alpha': 0.791758532339373, 'reg_lambda': 0.21639827079066043}. Best is trial 3 with value: 0.8787325024604797.\n",
      "[I 2025-05-16 21:06:37,672] Trial 6 finished with value: 0.8787782788276672 and parameters: {'n_estimators': 714, 'max_depth': 4, 'learning_rate': 0.04305179875210942, 'subsample': 0.8123809779052816, 'colsample_bytree': 0.6337333636966688, 'gamma': 3.358243203840954, 'reg_alpha': 0.5359676405271132, 'reg_lambda': 0.9215962254958254}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:39,386] Trial 7 finished with value: 0.8529370427131653 and parameters: {'n_estimators': 1120, 'max_depth': 4, 'learning_rate': 0.15411923411174844, 'subsample': 0.931404317618583, 'colsample_bytree': 0.6790260343573069, 'gamma': 0.9863713212937919, 'reg_alpha': 1.968539800070951, 'reg_lambda': 1.9635984690570971}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:41,071] Trial 8 finished with value: 0.864578902721405 and parameters: {'n_estimators': 830, 'max_depth': 6, 'learning_rate': 0.03036091646444091, 'subsample': 0.8396725768149271, 'colsample_bytree': 0.9116669913291464, 'gamma': 1.7115106143204328, 'reg_alpha': 1.147341076947569, 'reg_lambda': 1.807972322097879}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:42,622] Trial 9 finished with value: 0.8509045243263245 and parameters: {'n_estimators': 1121, 'max_depth': 3, 'learning_rate': 0.11401821810660387, 'subsample': 0.7640945147850557, 'colsample_bytree': 0.682826888659283, 'gamma': 0.111895112231154, 'reg_alpha': 0.8611539139966995, 'reg_lambda': 1.1382041345330252}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:43,767] Trial 10 finished with value: 0.859041690826416 and parameters: {'n_estimators': 597, 'max_depth': 5, 'learning_rate': 0.010879056741057228, 'subsample': 0.9999356494934775, 'colsample_bytree': 0.6053479655639225, 'gamma': 4.109019410076919, 'reg_alpha': 0.1818346837882529, 'reg_lambda': 0.5370450593412855}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:44,369] Trial 11 finished with value: 0.8540744781494141 and parameters: {'n_estimators': 354, 'max_depth': 3, 'learning_rate': 0.013091385862653989, 'subsample': 0.8712656794277023, 'colsample_bytree': 0.741124256813419, 'gamma': 3.645503311730544, 'reg_alpha': 0.43672187442322136, 'reg_lambda': 1.371115762811174}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:45,170] Trial 12 finished with value: 0.8766366243362427 and parameters: {'n_estimators': 496, 'max_depth': 3, 'learning_rate': 0.019223854538968858, 'subsample': 0.8928508325599593, 'colsample_bytree': 0.7551039733224811, 'gamma': 1.9628641589963054, 'reg_alpha': 1.2634353276182, 'reg_lambda': 0.8185119289046052}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:46,004] Trial 13 finished with value: 0.870114266872406 and parameters: {'n_estimators': 477, 'max_depth': 4, 'learning_rate': 0.055788636990551296, 'subsample': 0.8222960864531565, 'colsample_bytree': 0.6020660608405515, 'gamma': 3.3998059819877127, 'reg_alpha': 0.4677213103973523, 'reg_lambda': 0.4927823471966257}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:47,122] Trial 14 finished with value: 0.8747488260269165 and parameters: {'n_estimators': 660, 'max_depth': 4, 'learning_rate': 0.05303295333685318, 'subsample': 0.7019555307547448, 'colsample_bytree': 0.7560961185582213, 'gamma': 4.93896822960035, 'reg_alpha': 1.359337711684417, 'reg_lambda': 1.448719382307598}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:48,838] Trial 15 finished with value: 0.8543953895568848 and parameters: {'n_estimators': 927, 'max_depth': 5, 'learning_rate': 0.01834435649137096, 'subsample': 0.9008806578558319, 'colsample_bytree': 0.985658057141431, 'gamma': 0.32636853607881733, 'reg_alpha': 0.4745425478622477, 'reg_lambda': 0.800557107758097}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:49,967] Trial 16 finished with value: 0.8638833165168762 and parameters: {'n_estimators': 451, 'max_depth': 7, 'learning_rate': 0.04373922255129001, 'subsample': 0.8509417667850863, 'colsample_bytree': 0.7112924628891178, 'gamma': 1.3504087340618647, 'reg_alpha': 1.4486731089388691, 'reg_lambda': 1.1682602111757858}. Best is trial 6 with value: 0.8787782788276672.\n",
      "[I 2025-05-16 21:06:51,032] Trial 17 finished with value: 0.8838369846343994 and parameters: {'n_estimators': 689, 'max_depth': 3, 'learning_rate': 0.02088325468403403, 'subsample': 0.7981361770905044, 'colsample_bytree': 0.7867268764494787, 'gamma': 2.3307176518037775, 'reg_alpha': 1.0220252513414891, 'reg_lambda': 0.1474331484241016}. Best is trial 17 with value: 0.8838369846343994.\n",
      "[I 2025-05-16 21:06:53,354] Trial 18 finished with value: 0.8301845788955688 and parameters: {'n_estimators': 700, 'max_depth': 10, 'learning_rate': 0.07384022537143119, 'subsample': 0.7423601615251221, 'colsample_bytree': 0.8708583587913628, 'gamma': 2.2978847289853146, 'reg_alpha': 0.6087013945712176, 'reg_lambda': 0.04768680300936856}. Best is trial 17 with value: 0.8838369846343994.\n",
      "[I 2025-05-16 21:06:54,836] Trial 19 finished with value: 0.8705534934997559 and parameters: {'n_estimators': 849, 'max_depth': 4, 'learning_rate': 0.024019142363210316, 'subsample': 0.8025878914282486, 'colsample_bytree': 0.7921365565570226, 'gamma': 3.897499324405441, 'reg_alpha': 1.6650416969229278, 'reg_lambda': 0.45485718855012963}. Best is trial 17 with value: 0.8838369846343994.\n",
      "[I 2025-05-16 21:06:57,299] Trial 20 finished with value: 0.8629822134971619 and parameters: {'n_estimators': 976, 'max_depth': 7, 'learning_rate': 0.014943813016804357, 'subsample': 0.6865328521014978, 'colsample_bytree': 0.8729759159310575, 'gamma': 3.042715089334381, 'reg_alpha': 0.24521268893184367, 'reg_lambda': 0.27121519748006917}. Best is trial 17 with value: 0.8838369846343994.\n",
      "[I 2025-05-16 21:06:58,295] Trial 21 finished with value: 0.8872092962265015 and parameters: {'n_estimators': 590, 'max_depth': 3, 'learning_rate': 0.01918873943356969, 'subsample': 0.8091727499770712, 'colsample_bytree': 0.641656494260208, 'gamma': 1.6623894259248762, 'reg_alpha': 1.2111825027079655, 'reg_lambda': 1.65122802875083}. Best is trial 21 with value: 0.8872092962265015.\n",
      "[I 2025-05-16 21:06:59,298] Trial 22 finished with value: 0.8894966244697571 and parameters: {'n_estimators': 614, 'max_depth': 3, 'learning_rate': 0.03669469564491402, 'subsample': 0.7959807525411604, 'colsample_bytree': 0.6137191466442176, 'gamma': 2.134409326730858, 'reg_alpha': 1.1027362483581464, 'reg_lambda': 1.6762423026366131}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:00,249] Trial 23 finished with value: 0.8872979283332825 and parameters: {'n_estimators': 586, 'max_depth': 3, 'learning_rate': 0.02845896243847806, 'subsample': 0.7815243907791491, 'colsample_bytree': 0.6344534666261, 'gamma': 0.645485473993086, 'reg_alpha': 1.0943592765461634, 'reg_lambda': 1.645036751711832}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:01,362] Trial 24 finished with value: 0.8819602131843567 and parameters: {'n_estimators': 559, 'max_depth': 5, 'learning_rate': 0.03462494551776007, 'subsample': 0.7511112463253696, 'colsample_bytree': 0.6344826540275708, 'gamma': 0.6567128306806778, 'reg_alpha': 1.2185066840156067, 'reg_lambda': 1.6398725690393343}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:02,248] Trial 25 finished with value: 0.8867761492729187 and parameters: {'n_estimators': 542, 'max_depth': 3, 'learning_rate': 0.027150890848427103, 'subsample': 0.6016846113581746, 'colsample_bytree': 0.6497181967443277, 'gamma': 1.7532067435147347, 'reg_alpha': 1.4846719733274696, 'reg_lambda': 1.9865767945535806}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:03,014] Trial 26 finished with value: 0.8596668243408203 and parameters: {'n_estimators': 390, 'max_depth': 4, 'learning_rate': 0.010066470267354868, 'subsample': 0.7768479654390283, 'colsample_bytree': 0.6072226991050013, 'gamma': 0.6346677342963085, 'reg_alpha': 1.7642091937467774, 'reg_lambda': 1.6147284373800894}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:04,079] Trial 27 finished with value: 0.8792695999145508 and parameters: {'n_estimators': 636, 'max_depth': 3, 'learning_rate': 0.01515961304307636, 'subsample': 0.7182025258917669, 'colsample_bytree': 0.7127940344085796, 'gamma': 1.567528480016946, 'reg_alpha': 0.9807502227211562, 'reg_lambda': 1.5092192505849087}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:05,675] Trial 28 finished with value: 0.8780096173286438 and parameters: {'n_estimators': 772, 'max_depth': 5, 'learning_rate': 0.04038910181332902, 'subsample': 0.8555388879509616, 'colsample_bytree': 0.6773940477188679, 'gamma': 0.7761217697660996, 'reg_alpha': 1.2892238883014993, 'reg_lambda': 1.7778813181050992}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:08,327] Trial 29 finished with value: 0.8611756563186646 and parameters: {'n_estimators': 798, 'max_depth': 9, 'learning_rate': 0.07223924847919726, 'subsample': 0.8267751254383333, 'colsample_bytree': 0.6516005361936676, 'gamma': 1.8651892900055334, 'reg_alpha': 0.7782195080002705, 'reg_lambda': 1.782185648781897}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:09,260] Trial 30 finished with value: 0.8588591814041138 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.05415270350201675, 'subsample': 0.7806366536311756, 'colsample_bytree': 0.6239110737258484, 'gamma': 2.038308976715066, 'reg_alpha': 1.1743179918668105, 'reg_lambda': 1.664769874029841}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:10,176] Trial 31 finished with value: 0.8849961757659912 and parameters: {'n_estimators': 540, 'max_depth': 3, 'learning_rate': 0.022926622026209733, 'subsample': 0.629600144928262, 'colsample_bytree': 0.6547309847967673, 'gamma': 1.51313618935721, 'reg_alpha': 1.4632313512895676, 'reg_lambda': 1.9436279382993158}. Best is trial 22 with value: 0.8894966244697571.\n",
      "[I 2025-05-16 21:07:11,158] Trial 32 finished with value: 0.8897560834884644 and parameters: {'n_estimators': 605, 'max_depth': 3, 'learning_rate': 0.02973530558057803, 'subsample': 0.6138033991222325, 'colsample_bytree': 0.6469775291697203, 'gamma': 2.763622795872503, 'reg_alpha': 1.4970531303220864, 'reg_lambda': 1.9958453732430486}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:12,263] Trial 33 finished with value: 0.8851393461227417 and parameters: {'n_estimators': 610, 'max_depth': 4, 'learning_rate': 0.03132596176270678, 'subsample': 0.6733606054817738, 'colsample_bytree': 0.694344709868449, 'gamma': 2.7011644197374802, 'reg_alpha': 1.593603463071352, 'reg_lambda': 1.8329830355210053}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:13,458] Trial 34 finished with value: 0.8836302161216736 and parameters: {'n_estimators': 743, 'max_depth': 3, 'learning_rate': 0.016901259835914936, 'subsample': 0.9244394856858661, 'colsample_bytree': 0.6248272782410252, 'gamma': 2.596121926480374, 'reg_alpha': 1.1009473472514488, 'reg_lambda': 1.5071227297757703}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:15,091] Trial 35 finished with value: 0.8756292462348938 and parameters: {'n_estimators': 577, 'max_depth': 8, 'learning_rate': 0.03690013361237085, 'subsample': 0.6563394155920386, 'colsample_bytree': 0.6603018850225998, 'gamma': 1.1582323856145016, 'reg_alpha': 1.3550861845635687, 'reg_lambda': 1.7462620595061655}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:16,261] Trial 36 finished with value: 0.8872450590133667 and parameters: {'n_estimators': 640, 'max_depth': 4, 'learning_rate': 0.023335884373882346, 'subsample': 0.7323234994670796, 'colsample_bytree': 0.6966508624854142, 'gamma': 3.028741389727877, 'reg_alpha': 1.7595023247952248, 'reg_lambda': 1.8754415575913053}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:17,490] Trial 37 finished with value: 0.8472888469696045 and parameters: {'n_estimators': 646, 'max_depth': 4, 'learning_rate': 0.2376610046155304, 'subsample': 0.7391551513272921, 'colsample_bytree': 0.6961021914785795, 'gamma': 2.9923512897747524, 'reg_alpha': 1.8429157786526495, 'reg_lambda': 1.8660421238990272}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:18,581] Trial 38 finished with value: 0.8812975883483887 and parameters: {'n_estimators': 515, 'max_depth': 4, 'learning_rate': 0.02652592513499245, 'subsample': 0.614242005949974, 'colsample_bytree': 0.7224688402580309, 'gamma': 4.29981050975464, 'reg_alpha': 1.860537133557067, 'reg_lambda': 1.2702451638391241}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:21,296] Trial 39 finished with value: 0.8803297281265259 and parameters: {'n_estimators': 727, 'max_depth': 3, 'learning_rate': 0.047434521026502155, 'subsample': 0.7169336038827816, 'colsample_bytree': 0.6208203049942164, 'gamma': 3.2676476352736765, 'reg_alpha': 1.6887933458679845, 'reg_lambda': 1.8978905053652335}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:25,526] Trial 40 finished with value: 0.8806297183036804 and parameters: {'n_estimators': 873, 'max_depth': 5, 'learning_rate': 0.031868095589159415, 'subsample': 0.6394918364080531, 'colsample_bytree': 0.6658729024490454, 'gamma': 2.9652437598739922, 'reg_alpha': 1.5329772220214182, 'reg_lambda': 1.9997168413486273}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:27,914] Trial 41 finished with value: 0.8891936540603638 and parameters: {'n_estimators': 671, 'max_depth': 3, 'learning_rate': 0.021547756007933717, 'subsample': 0.7946464075113774, 'colsample_bytree': 0.6391010420329156, 'gamma': 2.2614766565815017, 'reg_alpha': 1.0529100622239305, 'reg_lambda': 1.6914278639901832}. Best is trial 32 with value: 0.8897560834884644.\n",
      "[I 2025-05-16 21:07:30,392] Trial 42 finished with value: 0.892414927482605 and parameters: {'n_estimators': 686, 'max_depth': 3, 'learning_rate': 0.023961403365515, 'subsample': 0.7869792280350976, 'colsample_bytree': 0.6006680762021221, 'gamma': 2.4406762215636855, 'reg_alpha': 0.9433811696912263, 'reg_lambda': 1.523233650171723}. Best is trial 42 with value: 0.892414927482605.\n",
      "[I 2025-05-16 21:07:32,955] Trial 43 finished with value: 0.888193666934967 and parameters: {'n_estimators': 689, 'max_depth': 3, 'learning_rate': 0.02884037680728784, 'subsample': 0.7634643515491283, 'colsample_bytree': 0.603241972770333, 'gamma': 2.1404151446351682, 'reg_alpha': 0.9216981097815481, 'reg_lambda': 1.5517361896810453}. Best is trial 42 with value: 0.892414927482605.\n",
      "[I 2025-05-16 21:07:35,288] Trial 44 finished with value: 0.8896450400352478 and parameters: {'n_estimators': 683, 'max_depth': 3, 'learning_rate': 0.03711176042144131, 'subsample': 0.7550340358378026, 'colsample_bytree': 0.6006043993254795, 'gamma': 2.0970443178696763, 'reg_alpha': 0.9069683639392505, 'reg_lambda': 1.5095971701350053}. Best is trial 42 with value: 0.892414927482605.\n",
      "[I 2025-05-16 21:07:38,154] Trial 45 finished with value: 0.8751569390296936 and parameters: {'n_estimators': 784, 'max_depth': 3, 'learning_rate': 0.06276889079212417, 'subsample': 0.8384356072279096, 'colsample_bytree': 0.6178620362812396, 'gamma': 2.5101216668806865, 'reg_alpha': 0.7331182283106952, 'reg_lambda': 1.381657009724099}. Best is trial 42 with value: 0.892414927482605.\n",
      "[I 2025-05-16 21:07:40,573] Trial 46 finished with value: 0.874325156211853 and parameters: {'n_estimators': 671, 'max_depth': 4, 'learning_rate': 0.03828683421032635, 'subsample': 0.8655977217658141, 'colsample_bytree': 0.6002351433945404, 'gamma': 2.194424953146599, 'reg_alpha': 0.8536754289097173, 'reg_lambda': 1.0454602334431027}. Best is trial 42 with value: 0.892414927482605.\n",
      "[I 2025-05-16 21:07:43,038] Trial 47 finished with value: 0.8855385780334473 and parameters: {'n_estimators': 738, 'max_depth': 3, 'learning_rate': 0.012423882600833979, 'subsample': 0.7939636798492792, 'colsample_bytree': 0.6731521483437802, 'gamma': 2.726508678103702, 'reg_alpha': 0.9874809642691579, 'reg_lambda': 1.3861469525440588}. Best is trial 42 with value: 0.892414927482605.\n",
      "[I 2025-05-16 21:07:46,001] Trial 48 finished with value: 0.8632694482803345 and parameters: {'n_estimators': 817, 'max_depth': 4, 'learning_rate': 0.10673801491245583, 'subsample': 0.9664638386168221, 'colsample_bytree': 0.6408170443744388, 'gamma': 2.438378210345426, 'reg_alpha': 0.7176589467076695, 'reg_lambda': 1.7267092369117056}. Best is trial 42 with value: 0.892414927482605.\n",
      "[I 2025-05-16 21:07:48,550] Trial 49 finished with value: 0.8778010606765747 and parameters: {'n_estimators': 625, 'max_depth': 5, 'learning_rate': 0.04830073822381678, 'subsample': 0.6940846207953596, 'colsample_bytree': 0.6182987115287186, 'gamma': 2.814917096677602, 'reg_alpha': 0.6150972758364853, 'reg_lambda': 1.5243266904953647}. Best is trial 42 with value: 0.892414927482605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 686, 'max_depth': 3, 'learning_rate': 0.023961403365515, 'subsample': 0.7869792280350976, 'colsample_bytree': 0.6006680762021221, 'gamma': 2.4406762215636855, 'reg_alpha': 0.9433811696912263, 'reg_lambda': 1.523233650171723}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Re-split to ensure clean training/validation split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 2),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 2),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_tr, y_tr)  # removed early stopping\n",
    "    preds = model.predict(X_val)\n",
    "    return r2_score(y_val, preds)\n",
    "\n",
    "# Optimize\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "29f981f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized R² Score: 0.8709053993225098\n",
      "Optimized MSE: 990197568.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Use best parameters from Optuna study\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# You may want to re-specify fixed params like random_state\n",
    "best_params[\"random_state\"] = 42\n",
    "\n",
    "# Train final model on full training set\n",
    "final_xgb_model = XGBRegressor(**best_params)\n",
    "final_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = final_xgb_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print(\"Optimized R² Score:\", r2_score(y_test, y_pred))\n",
    "print(\"Optimized MSE:\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "27de9238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 21:15:42,471] A new study created in memory with name: no-name-c4942386-8fb7-4fc6-b97b-73ed125ea9ab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 21:15:44,672] Trial 0 finished with value: 0.2226555790691261 and parameters: {'iterations': 830, 'depth': 5, 'learning_rate': 0.0966466423931404, 'l2_leaf_reg': 4.304040520108539, 'bagging_temperature': 0.9425233024067794, 'border_count': 86, 'random_strength': 7.001578246825316}. Best is trial 0 with value: 0.2226555790691261.\n",
      "[I 2025-05-16 21:15:49,504] Trial 1 finished with value: 0.23134822751090198 and parameters: {'iterations': 355, 'depth': 10, 'learning_rate': 0.1430307018057238, 'l2_leaf_reg': 4.746955337374125, 'bagging_temperature': 0.7646609368084064, 'border_count': 98, 'random_strength': 8.724165047454987}. Best is trial 0 with value: 0.2226555790691261.\n",
      "[I 2025-05-16 21:15:53,753] Trial 2 finished with value: 0.22769807821470966 and parameters: {'iterations': 999, 'depth': 9, 'learning_rate': 0.09126692647629417, 'l2_leaf_reg': 6.817546843483595, 'bagging_temperature': 0.7657586687650014, 'border_count': 52, 'random_strength': 1.0797700374652552}. Best is trial 0 with value: 0.2226555790691261.\n",
      "[I 2025-05-16 21:15:56,886] Trial 3 finished with value: 0.25388183504291506 and parameters: {'iterations': 464, 'depth': 9, 'learning_rate': 0.03630960400352655, 'l2_leaf_reg': 8.753783914441282, 'bagging_temperature': 0.0024545866943449512, 'border_count': 67, 'random_strength': 7.779650655342179}. Best is trial 0 with value: 0.2226555790691261.\n",
      "[I 2025-05-16 21:15:59,348] Trial 4 finished with value: 0.2219802196751726 and parameters: {'iterations': 685, 'depth': 6, 'learning_rate': 0.13176693161849962, 'l2_leaf_reg': 9.55090275501638, 'bagging_temperature': 0.35608152233178314, 'border_count': 113, 'random_strength': 9.760433836165435}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:00,781] Trial 5 finished with value: 0.2268506365591984 and parameters: {'iterations': 804, 'depth': 4, 'learning_rate': 0.2825785971854914, 'l2_leaf_reg': 8.34783487168664, 'bagging_temperature': 0.2465766075752739, 'border_count': 171, 'random_strength': 9.384267404695985}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:03,000] Trial 6 finished with value: 0.22583749412135912 and parameters: {'iterations': 320, 'depth': 9, 'learning_rate': 0.18101939455399166, 'l2_leaf_reg': 8.542475527684653, 'bagging_temperature': 0.6690363010349472, 'border_count': 66, 'random_strength': 0.5517189634322989}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:04,863] Trial 7 finished with value: 0.2445614776234546 and parameters: {'iterations': 756, 'depth': 3, 'learning_rate': 0.1139710469746889, 'l2_leaf_reg': 5.478993598276309, 'bagging_temperature': 0.23325821757270604, 'border_count': 41, 'random_strength': 0.6029277971048008}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:06,029] Trial 8 finished with value: 0.23252268363621628 and parameters: {'iterations': 531, 'depth': 5, 'learning_rate': 0.26982595907691936, 'l2_leaf_reg': 8.325287863207663, 'bagging_temperature': 0.018549981744852895, 'border_count': 71, 'random_strength': 4.080453649846893}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:17,459] Trial 9 finished with value: 0.24166448636787718 and parameters: {'iterations': 932, 'depth': 9, 'learning_rate': 0.0205447869449344, 'l2_leaf_reg': 7.971577844536853, 'bagging_temperature': 0.7546624565125604, 'border_count': 235, 'random_strength': 6.340418376924145}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:18,075] Trial 10 finished with value: 0.24690314394379684 and parameters: {'iterations': 109, 'depth': 7, 'learning_rate': 0.20075920464390107, 'l2_leaf_reg': 1.6910640709520326, 'bagging_temperature': 0.432877039731394, 'border_count': 145, 'random_strength': 3.6257763810041963}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:20,824] Trial 11 finished with value: 0.22633802225671998 and parameters: {'iterations': 705, 'depth': 6, 'learning_rate': 0.07715311676519665, 'l2_leaf_reg': 3.3285668384348033, 'bagging_temperature': 0.9843355560215639, 'border_count': 120, 'random_strength': 6.913741357302653}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:23,323] Trial 12 finished with value: 0.22372787066707925 and parameters: {'iterations': 648, 'depth': 7, 'learning_rate': 0.21981509363072496, 'l2_leaf_reg': 3.7667636943964284, 'bagging_temperature': 0.49032507253895175, 'border_count': 181, 'random_strength': 9.860164178357811}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:25,456] Trial 13 finished with value: 0.2265931705089933 and parameters: {'iterations': 857, 'depth': 5, 'learning_rate': 0.1456038599447502, 'l2_leaf_reg': 1.2819472451698015, 'bagging_temperature': 0.9421759675249658, 'border_count': 107, 'random_strength': 5.636093521364974}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:29,488] Trial 14 finished with value: 0.23699096201594605 and parameters: {'iterations': 621, 'depth': 6, 'learning_rate': 0.0632447301557618, 'l2_leaf_reg': 9.858170930116163, 'bagging_temperature': 0.33833988665747994, 'border_count': 131, 'random_strength': 7.916803581754832}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:32,954] Trial 15 finished with value: 0.23399143259332236 and parameters: {'iterations': 825, 'depth': 3, 'learning_rate': 0.11942616724888705, 'l2_leaf_reg': 6.154205144224497, 'bagging_temperature': 0.5852540578605405, 'border_count': 94, 'random_strength': 4.428200301921453}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:35,020] Trial 16 finished with value: 0.227050331683224 and parameters: {'iterations': 562, 'depth': 5, 'learning_rate': 0.1805117938238338, 'l2_leaf_reg': 2.686423688462562, 'bagging_temperature': 0.15563498662116304, 'border_count': 160, 'random_strength': 2.6866849058944435}. Best is trial 4 with value: 0.2219802196751726.\n",
      "[I 2025-05-16 21:16:42,883] Trial 17 finished with value: 0.22140019912549339 and parameters: {'iterations': 917, 'depth': 7, 'learning_rate': 0.053829690769610514, 'l2_leaf_reg': 4.584295834186418, 'bagging_temperature': 0.8632979254968719, 'border_count': 211, 'random_strength': 8.170540670132418}. Best is trial 17 with value: 0.22140019912549339.\n",
      "[I 2025-05-16 21:16:56,968] Trial 18 finished with value: 0.218972246188993 and parameters: {'iterations': 934, 'depth': 8, 'learning_rate': 0.06378833249535415, 'l2_leaf_reg': 6.620267795614605, 'bagging_temperature': 0.574695311969946, 'border_count': 211, 'random_strength': 8.597397212958958}. Best is trial 18 with value: 0.218972246188993.\n",
      "[I 2025-05-16 21:17:09,531] Trial 19 finished with value: 0.2186092771282953 and parameters: {'iterations': 999, 'depth': 8, 'learning_rate': 0.06034072938265689, 'l2_leaf_reg': 6.977446661219425, 'bagging_temperature': 0.6201334986457938, 'border_count': 215, 'random_strength': 8.390076648137942}. Best is trial 19 with value: 0.2186092771282953.\n",
      "[I 2025-05-16 21:17:21,434] Trial 20 finished with value: 0.24814926340559587 and parameters: {'iterations': 992, 'depth': 8, 'learning_rate': 0.0180177963437562, 'l2_leaf_reg': 6.944444726757719, 'bagging_temperature': 0.5837473428481394, 'border_count': 250, 'random_strength': 5.8083853715609575}. Best is trial 19 with value: 0.2186092771282953.\n",
      "[I 2025-05-16 21:17:31,707] Trial 21 finished with value: 0.2218577802538607 and parameters: {'iterations': 909, 'depth': 8, 'learning_rate': 0.05116765848669762, 'l2_leaf_reg': 5.9287699399851865, 'bagging_temperature': 0.8744091626205375, 'border_count': 204, 'random_strength': 8.340795978684918}. Best is trial 19 with value: 0.2186092771282953.\n",
      "[I 2025-05-16 21:17:42,303] Trial 22 finished with value: 0.22152475242732098 and parameters: {'iterations': 927, 'depth': 8, 'learning_rate': 0.05178352028370444, 'l2_leaf_reg': 7.103560555268304, 'bagging_temperature': 0.628775724726843, 'border_count': 213, 'random_strength': 8.72426150646795}. Best is trial 19 with value: 0.2186092771282953.\n",
      "[I 2025-05-16 21:17:49,983] Trial 23 finished with value: 0.2131172244459208 and parameters: {'iterations': 907, 'depth': 7, 'learning_rate': 0.09094272132622196, 'l2_leaf_reg': 5.029918349115874, 'bagging_temperature': 0.6941746125476821, 'border_count': 203, 'random_strength': 7.709115572461209}. Best is trial 23 with value: 0.2131172244459208.\n",
      "[I 2025-05-16 21:17:58,206] Trial 24 finished with value: 0.2162715383775825 and parameters: {'iterations': 751, 'depth': 8, 'learning_rate': 0.08823149097911917, 'l2_leaf_reg': 5.052726047948779, 'bagging_temperature': 0.5159574149702656, 'border_count': 193, 'random_strength': 7.329766639924291}. Best is trial 23 with value: 0.2131172244459208.\n",
      "[I 2025-05-16 21:18:19,807] Trial 25 finished with value: 0.22198414116709156 and parameters: {'iterations': 740, 'depth': 10, 'learning_rate': 0.0951129073836394, 'l2_leaf_reg': 5.293440406609725, 'bagging_temperature': 0.6902675646442041, 'border_count': 193, 'random_strength': 6.3955252954250374}. Best is trial 23 with value: 0.2131172244459208.\n",
      "[I 2025-05-16 21:18:28,027] Trial 26 finished with value: 0.21647673010107213 and parameters: {'iterations': 766, 'depth': 7, 'learning_rate': 0.11414592324724485, 'l2_leaf_reg': 7.634844524825846, 'bagging_temperature': 0.4786638243196074, 'border_count': 232, 'random_strength': 7.363973953574654}. Best is trial 23 with value: 0.2131172244459208.\n",
      "[I 2025-05-16 21:18:37,890] Trial 27 finished with value: 0.21365704786096096 and parameters: {'iterations': 772, 'depth': 7, 'learning_rate': 0.15923268296730203, 'l2_leaf_reg': 7.644576965331688, 'bagging_temperature': 0.4959468514975236, 'border_count': 232, 'random_strength': 7.204739663412659}. Best is trial 23 with value: 0.2131172244459208.\n",
      "[I 2025-05-16 21:18:42,571] Trial 28 finished with value: 0.2179669022171083 and parameters: {'iterations': 590, 'depth': 6, 'learning_rate': 0.17247990425579507, 'l2_leaf_reg': 2.7452780751122337, 'bagging_temperature': 0.4063820881365307, 'border_count': 250, 'random_strength': 4.831699366770627}. Best is trial 23 with value: 0.2131172244459208.\n",
      "[I 2025-05-16 21:18:45,673] Trial 29 finished with value: 0.2268701638630242 and parameters: {'iterations': 859, 'depth': 7, 'learning_rate': 0.2386925034826674, 'l2_leaf_reg': 5.005704395562442, 'bagging_temperature': 0.5426770108112763, 'border_count': 187, 'random_strength': 7.026308318702916}. Best is trial 23 with value: 0.2131172244459208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'iterations': 907, 'depth': 7, 'learning_rate': 0.09094272132622196, 'l2_leaf_reg': 5.029918349115874, 'bagging_temperature': 0.6941746125476821, 'border_count': 203, 'random_strength': 7.709115572461209}\n",
      "MSE: 0.19565940704194254\n",
      "R² Score: 0.8506882887015954\n"
     ]
    }
   ],
   "source": [
    "#catboost\n",
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example data (replace this with your actual dataset)\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optuna objective\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-9, 10),\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"verbose\": 0,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=30, verbose=0)\n",
    "    preds = model.predict(X_val)\n",
    "    return mean_squared_error(y_val, preds)\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30, timeout=600)\n",
    "\n",
    "# Train final model\n",
    "best_params = study.best_params\n",
    "final_model = CatBoostRegressor(**best_params, loss_function=\"RMSE\", verbose=0, random_state=42)\n",
    "final_model.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = final_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R² Score:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
